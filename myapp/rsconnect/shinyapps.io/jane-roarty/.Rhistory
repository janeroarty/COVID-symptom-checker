within_outer = mean(within_outer)
)
names(pred_summary)[3] <- paste0("within_", prob_inner*100)
names(pred_summary)[4] <- paste0("within_", prob_outer*100)
pred_summary
}
# Visual summary: add *actual* entire season batting averages in red
g_all + geom_point(aes(x = c(1:18), y = all_bb$SeasonAverage), color = "red")
# Numerical summary: posterior predictive accuracy
prediction_summary(y = all_bb$SeasonAverage,
yrep = predictions_all)
prediction_summary <- function(y, yrep, prob_inner = 0.5, prob_outer = 0.95){
# This function summarizes the predictions across all cases
pred_data <- prediction_summary_data(y, yrep, prob_inner = prob_inner, prob_outer = prob_outer) %>%
mutate(error = y - post_median) %>%
mutate(error_scaled = error / post_mad) %>%
mutate(within_inner = (y >= l_inner) & (y <= u_inner)) %>%
mutate(within_outer = (y >= l_outer) & (y <= u_outer))
pred_summary <- pred_data %>%
summarize(mae = median(abs(error)),
mae_scaled = median(abs(error_scaled)),
within_inner = mean(within_inner),
within_outer = mean(within_outer)
)
names(pred_summary)[3] <- paste0("within_", prob_inner*100)
names(pred_summary)[4] <- paste0("within_", prob_outer*100)
pred_summary
}
# Visual summary: add *actual* entire season batting averages in red
g_all + geom_point(aes(x = c(1:18), y = all_bb$SeasonAverage), color = "red")
# Numerical summary: posterior predictive accuracy
prediction_summary(y = all_bb$SeasonAverage,
yrep = predictions_all)
set.seed(454)
classifications <- posterior_predict(
model_sim,
newdata = model_data)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(janitor)
library(reshape2)
library(tidyr)
library(rstan)
library(rstanarm)
library(bayesplot)
# Load the data
library(rattle)
data(weatherAUS)
# Take a sub-sample of the data
set.seed(84735)
weather <- weatherAUS %>%
filter(Location == "Perth") %>%
mutate(Location = droplevels(Location)) %>%
select(RainTomorrow, RainToday, Humidity3pm, Humidity9am) %>%
na.omit() %>%
sample_n(1000)
names(weather) <- tolower(names(weather))
# Check out some relationships
ggplot(weather, aes(x = raintoday, fill = raintomorrow)) +
geom_bar()
ggplot(weather, aes(x = humidity9am, fill = raintomorrow)) +
geom_density(alpha = 0.5)
ggplot(weather, aes(x = humidity3pm, fill = raintomorrow)) +
geom_density(alpha = 0.5)
ggplot(weather, aes(x = humidity9am, y = humidity3pm, color = raintomorrow)) +
geom_point()
set.seed(454)
model_sim <- stan_glm(
raintomorrow ~ humidity9am + humidity3pm, data = weather,
family = binomial,
chains = 4, iter = 2*5000, refresh = 0)
pp_check(model_sim)
mcmc_trace(model_sim)
mcmc_dens_overlay(model_sim)
model_summary <- summary(model_sim)
head(as.data.frame(model_sim), -2)
model_data <- weather %>%
select(raintomorrow, humidity3pm, humidity9am) %>%
na.omit()
my_data <- data.frame(raintoday = "Yes", humidity9am = 70, humidity3pm = 75)
set.seed(454)
prob_predictions <- posterior_linpred(
model_sim,
newdata = my_data,
transform = FALSE)
set.seed(454)
prob_predictions <- posterior_linpred(
model_sim,
newdata = my_data,
transform = TRUE)
# Posterior model for each day in data set
set.seed(454)
classifications <- posterior_predict(
model_sim,
newdata = model_data)
# Summarize the probability of rain for each day
prob_rain <- colMeans(classifications)
# Classify each day using 50/50 cutoff
classification <- prob_rain >= 0.5
# Confusion matrix
table(model_data$raintomorrow, classification)
set.seed(454)
classifications <- posterior_predict(
model_sim,
newdata = model_data)
# Summarize the probability of rain for each day
prob_rain <- colMeans(classifications)
# Classify each day using 50/50 cutoff
classification <- prob_rain >= 0.5
# Confusion matrix
table(model_data$raintomorrow, classification)
library(janitor)
weather %>%
tabyl(raintomorrow)
weather %>%
tabyl(raintomorrow, raintoday)
(.221 * 0.4706)/.201
# Calculate sample mean and sd for each Y group
weather %>%
group_by(raintomorrow) %>%
summarize(mean(humidity3pm), sd(humidity3pm))
# Plot the Normal models with these mean and sd settings
ggplot(weather, aes(x = humidity3pm, fill = raintomorrow)) +
geom_density(alpha = 0.5) +
stat_function(fun = dnorm, args = list(mean = 42.5, sd = 13.6), color = "red") +
stat_function(fun = dnorm, args = list(mean = 63.8, sd = 16.6), color = "blue")
# Likelihood when Y = 1
dnorm(75, mean = 63.8, sd = 16.6)
# Likelihood when Y = 0
dnorm(75, mean = 42.5, sd = 13.6)
(0.221 * 0.0191) / ((0.779*0.0017) + (0.221*0.0191))
ggplot(weather, aes(x = humidity9am, y = humidity3pm, color = raintoday)) +
geom_point() +
facet_grid(~ raintomorrow)
library(e1071)
naive <- naiveBayes(raintomorrow ~ raintoday + humidity9am + humidity3pm, data = weather)
library(e1071)
naive <- naiveBayes(raintomorrow ~ raintoday + humidity9am + humidity3pm, data = weather)
classifications <- predict(naive, weather)
library(e1071)
naive <- naiveBayes(raintomorrow ~ raintoday + humidity9am + humidity3pm, data = weather)
classifications <- predict(naive, weather)
table(weather$raintomorrow, classifications)
library(dplyr)
get_sim_data <- function(n, p_A_IV0, p_A_IV1) {
p_AfromIV <- dplyr::case_when(
IV==1 ~ p_A_IV1,
IV==0 ~ p_A_IV0
)
p_AfromC <- dplyr::case_when(
C==1 ~ 0.5,
C==0 ~ 0.2
)
p_A <- p_AfromIV*p_AfromC
A <- rbinom(n, size = 1, prob = p_A)
A_IVdo0 <- rbinom(n, size = 1, prob = p_A_IVdo0)
A_IVdo1 <- rbinom(n, size = 1, prob = p_A_IVdo1)
p_YfromA <- dplyr::case_when(
A==1 ~ 0.6,
A==0 ~ 0.3
)
p_YfromC <- dplyr::case_when(
C==1 ~ 0.7,
C==0 ~ 0.4
)
p_Y <- p_YfromA*p_YfromC
Y <- rbinom(n, size = 1, prob = p_Y)
Y_Ado0 <- rbinom(n, size = 1, prob = p_Y_Ado0)
Y_Ado1 <- rbinom(n, size = 1, prob = p_Y_Ado1)
sim_data <- data.frame(IV, C, A, A_IVdo0, A_IVdo1, Y, Y_Ado0, Y_Ado1)
sim_data
}
library(dplyr)
get_sim_data <- function(n, p_A_IV0, p_A_IV1) {
C <- rbinom(n, size = 1, prob = .5)
IV <- rbinom(n, size = 1, prob = .5)
p_AfromIV <- dplyr::case_when(
IV==1 ~ p_A_IV1,
IV==0 ~ p_A_IV0
)
p_AfromC <- dplyr::case_when(
C==1 ~ 0.5,
C==0 ~ 0.2
)
p_A <- p_AfromIV*p_AfromC
A <- rbinom(n, size = 1, prob = p_A)
A_IVdo0 <- rbinom(n, size = 1, prob = p_A_IVdo0)
A_IVdo1 <- rbinom(n, size = 1, prob = p_A_IVdo1)
p_YfromA <- dplyr::case_when(
A==1 ~ 0.6,
A==0 ~ 0.3
)
p_YfromC <- dplyr::case_when(
C==1 ~ 0.7,
C==0 ~ 0.4
)
p_Y <- p_YfromA*p_YfromC
Y <- rbinom(n, size = 1, prob = p_Y)
Y_Ado0 <- rbinom(n, size = 1, prob = p_Y_Ado0)
Y_Ado1 <- rbinom(n, size = 1, prob = p_Y_Ado1)
sim_data <- data.frame(IV, C, A, A_IVdo0, A_IVdo1, Y, Y_Ado0, Y_Ado1)
sim_data
}
get_ace <- function(data) {
}
get_cace <- function(data) {
data_subs <- data %>%
filter()
}
get_ace <- function(data) {
data_subs <- data %>%
filter(A==1)
}
get_ace
get_ace
get_ace <- function(data) {
sum(data$Y_Ado1==1)/n
sum(data$Y_Ado0==1)/n
(sum(data$Y_Ado1==1)/n)-(sum(data$Y_Ado0==1)/n)
}
get_ace
get_ace <- function(data) {
mean(data$Y_Ado1==1)
mean(data$Y_Ado0==1)
mean(sum(data$Y_Ado1==1)/n)-(sum(data$Y_Ado0==1)))
get_ace <- function(data) {
mean(data$Y_Ado1==1)
mean(data$Y_Ado0==1)
mean(sum(data$Y_Ado1==1)/n)-(sum(data$Y_Ado0==1))
}
get_ace
library(dplyr)
get_sim_data <- function(n, p_A_IV0, p_A_IV1) {
C <- rbinom(n, size = 1, prob = .5)
IV <- rbinom(n, size = 1, prob = .5)
p_AfromIV <- dplyr::case_when(
IV==1 ~ p_A_IV1,
IV==0 ~ p_A_IV0
)
p_AfromC <- dplyr::case_when(
C==1 ~ 0.5,
C==0 ~ 0.2
)
p_A <- p_AfromIV*p_AfromC
A <- rbinom(n, size = 1, prob = p_A)
p_A_IVdo0 <- p_A_IVO*p_AfromC
p_A_IVdo1 <- p_A_IV1*p_AfromC
A_IVdo0 <- rbinom(n, size = 1, prob = p_A_IVdo0)
A_IVdo1 <- rbinom(n, size = 1, prob = p_A_IVdo1)
p_YfromA <- dplyr::case_when(
A==1 ~ 0.6,
A==0 ~ 0.3
)
p_YfromC <- dplyr::case_when(
C==1 ~ 0.7,
C==0 ~ 0.4
)
p_Y <- p_YfromA*p_YfromC
Y <- rbinom(n, size = 1, prob = p_Y)
Y_Ado0 <- rbinom(n, size = 1, prob = p_Y_Ado0)
Y_Ado1 <- rbinom(n, size = 1, prob = p_Y_Ado1)
sim_data <- data.frame(IV, C, A, A_IVdo0, A_IVdo1, Y, Y_Ado0, Y_Ado1)
sim_data
}
get_ace <- function(data) {
mean(data$Y_Ado1==1)
mean(data$Y_Ado0==1)
mean(sum(data$Y_Ado1==1)/n)-(sum(data$Y_Ado0==1))
}
get_ace <- function(data) {
mean(data$Y_Ado1==1)
mean(data$Y_Ado0==1)
(mean(data$Y_Ado1==1))-(mean(data$Y_Ado0==1))
}
library(dplyr)
get_sim_data <- function(n, p_A_IV0, p_A_IV1) {
C <- rbinom(n, size = 1, prob = .5)
IV <- rbinom(n, size = 1, prob = .5)
p_AfromIV <- dplyr::case_when(
IV==1 ~ p_A_IV1,
IV==0 ~ p_A_IV0
)
p_AfromC <- dplyr::case_when(
C==1 ~ 0.5,
C==0 ~ 0.2
)
p_A <- p_AfromIV*p_AfromC
A <- rbinom(n, size = 1, prob = p_A)
p_A_IVdo0 <- p_A_IVO*p_AfromC
p_A_IVdo1 <- p_A_IV1*p_AfromC
A_IVdo0 <- rbinom(n, size = 1, prob = p_A_IVdo0)
A_IVdo1 <- rbinom(n, size = 1, prob = p_A_IVdo1)
p_YfromA <- dplyr::case_when(
A==1 ~ 0.6,
A==0 ~ 0.3
)
p_YfromC <- dplyr::case_when(
C==1 ~ 0.7,
C==0 ~ 0.4
)
p_Y <- p_YfromA*p_YfromC
Y <- rbinom(n, size = 1, prob = p_Y)
p_Y_Ado0 <- 0.3*p_YfromC
p_Y_Ado1 <- 0.6*p_YfromC
Y_Ado0 <- rbinom(n, size = 1, prob = p_Y_Ado0)
Y_Ado1 <- rbinom(n, size = 1, prob = p_Y_Ado1)
sim_data <- data.frame(IV, C, A, A_IVdo0, A_IVdo1, Y, Y_Ado0, Y_Ado1)
sim_data
}
```{r}
get_ace <- function(data) {
mean(data$Y_Ado1==1)
mean(data$Y_Ado0==1)
(mean(data$Y_Ado1==1))-(mean(data$Y_Ado0==1))
}
get_ace
get_cace <- function(data) {
data_subs <- data %>%
filter(A_IVdo0==0 & A_IVdo1==1)
}
mean(data_subs$Y_Ado1==1)-mean(data_subs$Y_Ado0==1)
get_cace <- function(data) {
data_subs <- data %>%
filter(A_IVdo0==0 & A_IVdo1==1)
mean(data_subs$Y_Ado1==1)-mean(data_subs$Y_Ado0==1)
}
get_cace
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(janitor)
library(reshape2)
library(tidyr)
library(rstan)
library(rstanarm)
library(bayesplot)
# Load 1970 data
bb <- read.csv("https://www.macalester.edu/~ajohns24/data/BattingAverage1970.csv")
# Define 1969 batting averages
bb <- bb %>%
mutate(BA_1969 = c(0.345, 0.308, 0.296, 0.270, 0.232,
0.254, 0.273, 0.130, 0.289, 0.235, 0.297, 0.236,
0.253, 0.286, 0.293, 0.260, 0.256, 0.225))
# UNexchangeable hierarchical model
set.seed(454)
model_4 <- stan_glmer(
cbind(Hits, AtBats - Hits) ~ BA_1969 + (1 | LastName),
data = bb, family = binomial,
chains = 4, iter = 2*5000, refresh = 0)
# Graphical summaries
mcmc_trace(model_4)
# UNexchangeable hierarchical model
set.seed(454)
model_4 <- stan_glmer(
cbind(Hits, AtBats - Hits) ~ BA_1969 + (1 | LastName),
data = bb, family = binomial,
chains = 4, iter = 2*5000, refresh = 0)
# Graphical summaries
mcmc_trace(model_4)
mcmc_dens_overlay(model_4)
install.packages('blogdown')
blogdown::install_hugo()
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(rstan)
library(rstanarm)
library(bayesplot)
library(gridExtra)
library(reshape2)
library(tidyr)
density_model1 <- mcmc_dens(model_1, pars = "(Intercept)") #+ lims(x = c(___,___))
density_model1
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(rstan)
library(rstanarm)
library(bayesplot)
library(gridExtra)
library(reshape2)
library(tidyr)
sleep <- read.csv("https://www.macalester.edu/~ajohns24/Data/SleepStudy.csv")
model_1 <- readRDS(gzcon(url("https://www.macalester.edu/~ajohns24/data/stat454/hw_9_model_1.rds")))
# Reaction ~ Days + (1 + Days | Subject)
mcmc_trace(model_1)
mcmc_dens_overlay(model_1)
model_2 <- readRDS(gzcon(url("https://www.macalester.edu/~ajohns24/data/stat454/hw_9_model_2.rds")))
# Reaction ~ (1 | Subject)
mcmc_trace(model_2)
mcmc_dens_overlay(model_2)
model_3 <- readRDS(gzcon(url("https://www.macalester.edu/~ajohns24/data/stat454/hw_9_model_3.rds")))
# Reaction ~ Days
mcmc_trace(model_3)
mcmc_dens_overlay(model_3)
model_4 <- readRDS(gzcon(url("https://www.macalester.edu/~ajohns24/data/stat454/hw_9_model_4.rds")))
# Reaction ~ Days + (1 + Days | Subject)
mcmc_trace(model_4)
mcmc_dens_overlay(model_4)
density_model1 <- mcmc_dens(model_1, pars = "(Intercept)") #+ lims(x = c(___,___))
density_model1
#250 - 300
density_model2 <- mcmc_dens(model_2, pars = "(Intercept)") + lims(x = c(250,400))
density_model2
density_model1 <- mcmc_dens(model_1, pars = "(Intercept)") + lims(x = c(250,350))
density_model1
density_model2 <- mcmc_dens(model_2, pars = "(Intercept)") + lims(x = c(250,350))
density_model2
density_model1 <- mcmc_dens(model_1, pars = "(Intercept)") + lims(x = c(250,350))
density_model1
density_model2 <- mcmc_dens(model_2, pars = "(Intercept)") + lims(x = c(250,350))
density_model2
set.seed(454)
density_model1 <- mcmc_dens(model_1, pars = "(Intercept)") + lims(x = c(250,350))
density_model1
set.seed(454)
density_model2 <- mcmc_dens(model_2, pars = "(Intercept)") + lims(x = c(250,350))
density_model2
model_1 <- readRDS(gzcon(url("https://www.macalester.edu/~ajohns24/data/stat454/hw_9_model_1.rds")))
# Reaction ~ Days + (1 + Days | Subject)
model_2 <- readRDS(gzcon(url("https://www.macalester.edu/~ajohns24/data/stat454/hw_9_model_2.rds")))
# Reaction ~ (1 | Subject)
set.seed(454)
density_model1 <- mcmc_dens(model_1, pars = "(Intercept)") + lims(x = c(250,350))
density_model1
set.seed(454)
density_model2 <- mcmc_dens(model_2, pars = "(Intercept)") + lims(x = c(250,350))
density_model2
set.seed(454)
density_model1 <- mcmc_dens(model_1, pars = "(Intercept)") + lims(x = c(250,400))
density_model1
set.seed(454)
density_model2 <- mcmc_dens(model_2, pars = "(Intercept)") + lims(x = c(250,400))
density_model2
mcmc_dens(model_2, pars = pars = sigma, transformations = sqrt)
mcmc_dens(model_2, pars =  sigma, transformations = sqrt)
mcmc_dens(model_2, pars= sigma, transformations = sqrt)
mcmc_dens(model_2, pars= ("sigma"), transformations = sqrt)
mcmc_dens(model_2, pars= ("sigma"),transformations = sqrt)+ lims(x = c(250,350))
mcmc_dens(model_2, pars= ("Sigma[subject:(Intercept),(Intercept)]"), transformations = sqrt)
mcmc_dens(model_2, pars= ("Sigma[subject:(sigma),(sigma)]"), transformations = sqrt)
mcmc_dens(model_2, pars= ("sigma[subject:(Intercept),(Intercept)]"), transformations = sqrt)
mcmc_dens(model_2, pars= ("sigma"),transformations = sqrt)
mcmc_dens(model_2, pars= ("sigma"))
mcmc_dens(model_2, pars= ("sigma")) + lims(x = c(35,55))
mcmc_dens(model_2, pars= ("Sigma[Subject:(Intercept),(Intercept)]"), transformations = sqrt)
mcmc_dens(model_2, pars= ("Sigma[Subject:(Intercept),(Intercept)]"), transformations = sqrt) + lims(x = c(15,70))
mcmc_dens(model_2, pars= ("Sigma[Subject:(Intercept),(Intercept)]"), transformations = sqrt) + lims(x = c(15,80))
model_2_df <- as.array(model_2) %>%
melt %>%
pivot_wider(names_from = parameters, values_from = value)
model_2_df <- model_2_df %>%
mutate(sigma_sq_w = `sigma`, sigma_sq_b = `Sigma[Subject:(Intercept),(Intercept)]`) %>%
mutate(correlation = sigma_sq_b/(sigma_sq_b+sigma_sq_w))
model_2_df
density <- ggplot(data=sleep, aes(x=correlation)) + geom_density()
density
density <- ggplot(data=model_2_df, aes(x=correlation)) + geom_density()
density
summary(model_4)
as.data.frame(summary(model_4))
summary(model_4)
a = 251.5 - 31.7
b =  10.5 - 9.1
a
b
a = 251.5 + 31.7
b =  10.5 + 9.1
a
b
c = 251.5 - 36.9
d =  10.5 - 9.2
c
d
set.seed(454)
predictions <- posterior_predict(
model_4,
newdata = sleep)
new_sleep <- data.frame(Days = 9, Subject = 308)
set.seed(454)
predictions <- posterior_predict(
model_4,
newdata = new_sleep)
head(predictions)
density <- ggplot(data=predictions, aes(x=Days)) + geom_density()
density <- data.frame(ggplot(data=predictions, aes(x=Days)) + geom_density())
set.seed(454)
predictions <- data.fram(posterior_predict(
model_4,
newdata = new_sleep))
set.seed(454)
predictions <- data.frame(posterior_predict(
model_4,
newdata = new_sleep))
head(predictions)
density <- ggplot(data=predictions, aes(x=Days)) + geom_density()
density
head(predictions)
density <- ggplot(data=predictions, aes(x=X1)) + geom_density()
density
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(rstan)
library(rstanarm)
library(bayesplot)
library(gridExtra)
library(reshape2)
library(tidyr)
.as.data.frame(summary(model_4))
as.data.frame(summary(model_4))
